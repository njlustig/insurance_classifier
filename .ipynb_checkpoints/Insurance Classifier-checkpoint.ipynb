{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d927526",
   "metadata": {},
   "source": [
    "# Car Insurance Claims Classifier Project\n",
    "This is a car insurance classifier which uses data from  to predict whether or not a person will file a claim for the purposes of identifying drivers who are likely to file an insurance claim.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95104e25",
   "metadata": {},
   "source": [
    "> ## Table of Contents\n",
    "> 1. Data Acquisition\n",
    "> 2. Data Preparation  \n",
    "    a. Train and Test Sets  \n",
    "    b. Transformation Pipelines   \n",
    ">3. Data Transformation  \n",
    ">4. Models  \n",
    ">5. Evaluation\n",
    ">6. Further Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb528589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "RANDOM_STATE=2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7e5e7",
   "metadata": {},
   "source": [
    "### 1. Data Acquisition\n",
    "The data used for this project is available at [this kaggle page](https://www.kaggle.com/sagnik1511/car-insurance-data). We'll load the data from our filesystem into a data frame after saving the dataset locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    #load data\n",
    "    file_path = Path('./Car_Insurance_Claim.csv')\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df.drop(['ID'], axis=1) #drop ID\n",
    "\n",
    "    # convert binary cols to bools\n",
    "    df['VEHICLE_OWNERSHIP'] = (df['VEHICLE_OWNERSHIP']==1.0)\n",
    "    df['MARRIED'] = (df['MARRIED']==1.0)\n",
    "    df['CHILDREN'] = (df['CHILDREN']==1.0)\n",
    "    df['OUTCOME'] = (df['OUTCOME']==1.0)\n",
    "\n",
    "    #convert zipcode to string\n",
    "    df['POSTAL_CODE'] = df['POSTAL_CODE'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721c3ef",
   "metadata": {},
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ffd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_set(df):\n",
    "    #split into train and test sets\n",
    "    train, test = train_test_split(df, test_size=.2, random_state=2021)\n",
    "\n",
    "    X_train = train.drop(['OUTCOME'], axis=1) # drop labels\n",
    "    y_train = train[['OUTCOME']] # only label vector\n",
    "    y_train = (y_train==1.0) # to bool\n",
    "    y_train = y_train.values.ravel() #to ndarray and transpose vector\n",
    "\n",
    "    X_test = test.drop(['OUTCOME'], axis=1)\n",
    "    y_test = test[['OUTCOME']]\n",
    "    y_test = (y_test==1.0)\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get split train and test data\n",
    "X_train, y_train, X_test, y_test = split_data_set(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88f89c",
   "metadata": {},
   "source": [
    "### 3. Data Transformation\n",
    "Next, we'll write a custom transformer to select columns for a pd.DataFrame.  Then, we'll build numerical and categorical pipelines for the respective data types.\n",
    "\n",
    "Below are the transforms that will be applied:\n",
    "    \n",
    "**Categorical Variables**\n",
    "- One hot encoding\n",
    "\n",
    "**Numerical Variables**\n",
    "- Impute missing values with the median of that column\n",
    "- Normalize the data with respect to the standard deviation and the mean of the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(df):\n",
    "    #numerical pipeline\n",
    "    numerics = ['int64', 'float64']\n",
    "    non_numerics = ['object', 'bool']\n",
    "    \n",
    "    num_cols = df.select_dtypes(include=numerics).columns\n",
    "    cat_cols = df.select_dtypes(include=non_numerics).columns\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "         ('selector', DataFrameSelector(num_cols)), #select num cols\n",
    "         ('imputer', SimpleImputer(strategy=\"median\")), #impute the missing values and fill with median\n",
    "         ('std_scaler', StandardScaler()), # z = (x-u)/std(x)   \n",
    "    ])\n",
    "    \n",
    "    cat_pipeline = Pipeline([\n",
    "         ('selector', DataFrameSelector(cat_cols)),\n",
    "         ('one_hot_encoder', OneHotEncoder()),\n",
    "    ])\n",
    "        \n",
    "    full_pipeline = FeatureUnion(transformer_list=[\n",
    "         (\"num_pipeline\", num_pipeline),\n",
    "         (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the transformer pipeline\n",
    "pipeline = build_pipeline(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c627da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = pipeline.fit_transform(X_train) # get transformed data to feed to the classifier\n",
    "X_test_prepared = pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3538e53",
   "metadata": {},
   "source": [
    "### 4. Models\n",
    "\n",
    "We're going to train each of the models on the training set first, and then train each model with cross validation to evaluate the models' generalizability.\n",
    "\n",
    "First, we instantiate each of the types of models that we want to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1fe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=RANDOM_STATE) #random state for reproducibility since SGD is stochastic\n",
    "knn_clf = KNeighborsRegressor(n_neighbors=1) # n=1 for binary classifier\n",
    "logit_clf = LogisticRegression()\n",
    "linear_svm_clf = LinearSVC(C=1, loss=\"hinge\", random_state=RANDOM_STATE, max_iter=10000) #random state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1cc05",
   "metadata": {},
   "source": [
    "Next, we'll train each model on the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train_prepared, y_train)\n",
    "knn_clf.fit(X_train_prepared, y_train)\n",
    "logit_clf.fit(X_train_prepared, y_train)\n",
    "linear_svm_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93e30b",
   "metadata": {},
   "source": [
    "Now, we can get predictions for the training set from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_sgd = sgd_clf.predict(X_train_prepared)\n",
    "y_train_pred_knn = knn_clf.predict(X_train_prepared)\n",
    "y_train_pred_logit = logit_clf.predict(X_train_prepared)\n",
    "y_train_pred_lin_svm = linear_svm_clf.predict(X_train_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2054fe9",
   "metadata": {},
   "source": [
    "Next, we get the predictions for each model using 3-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_sgd_cv = cross_val_predict(sgd_clf, X_train_prepared, y_train, cv=3)\n",
    "y_train_pred_knn_cv = cross_val_predict(knn_clf, X_train_prepared, y_train, cv=3, method=\"predict\")\n",
    "y_train_pred_logit_cv = cross_val_predict(logit_clf, X_train_prepared, y_train, cv=3, method=\"predict\")\n",
    "y_train_pred_lin_svm_cv = cross_val_predict(linear_svm_clf, X_train_prepared, y_train, cv=3, method=\"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64922340",
   "metadata": {},
   "source": [
    "### 5. Evaluation\n",
    "\n",
    "Now that all of the models are trained, we can get the evaluation metrics for both sets of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(y_train, y_train_pred):\n",
    "    confusion = confusion_matrix(y_train, y_train_pred)\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    precision = precision_score(y_train, y_train_pred)\n",
    "    recall = recall_score(y_train, y_train_pred)\n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    \n",
    "    return [confusion, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics for models trained with the training set\n",
    "sgd_metrics = get_model_metrics(y_train, y_train_pred_sgd)\n",
    "knn_metrics = get_model_metrics(y_train, y_train_pred_knn)\n",
    "logit_metrics = get_model_metrics(y_train, y_train_pred_logit)\n",
    "linear_svm_metrics = get_model_metrics(y_train, y_train_pred_lin_svm)\n",
    "\n",
    "#metrics for models trained with CV on the training set\n",
    "sgd_cv_metrics = get_model_metrics(y_train, y_train_pred_sgd_cv)\n",
    "knn_cv_metrics = get_model_metrics(y_train, y_train_pred_knn_cv)\n",
    "logit_cv_metrics = get_model_metrics(y_train, y_train_pred_logit_cv)\n",
    "linear_svm_cv_metrics = get_model_metrics(y_train, y_train_pred_lin_svm_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78739ac8",
   "metadata": {},
   "source": [
    "And now, we can print the results and compare the models' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_metrics(title, metrics):\n",
    "    conf, acc, prec, rec, f1 = metrics\n",
    "    print(f\"Performance metrics for {title}:\\n\")\n",
    "    print(conf, \"\\n\")\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"F1 Score: \", f1, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_metrics(\"SGD Classifier-No CV\", sgd_metrics)\n",
    "print_model_metrics(\"SGD Classifier-With CV\", sgd_cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92086a7e",
   "metadata": {},
   "source": [
    "As we can see here, the model is generalizing well, since we aren't seeing much difference in the performance on the cross-validated sets versus the training set.  Let's see if either of the other models have better predictive power.  Next up is the KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b48f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_metrics(\"KNN Classifier-No CV\", knn_metrics)\n",
    "print_model_metrics(\"KNN Classifier-With CV\", knn_cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99190e8",
   "metadata": {},
   "source": [
    "Here, we can see that the KNN model is badly overfitting and won't generalize to unseen data.  We can consider simplifying the model by removing some features, or opt to eliminate this model entirely.\n",
    "\n",
    "Next, let's check out how the logistic regression classifier fared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ca43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_metrics(\"Logit Classifier-No CV\", logit_metrics)\n",
    "print_model_metrics(\"Logit Classifier-With CV\", logit_cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ca921",
   "metadata": {},
   "source": [
    "Good news!  The logit classifier is generalizing well, ***and***  performs better on all evaluation metrics than the SGD classifier!  This looks like a winner thus far, but we still aren't achieving particularly high accuracy.  Perhaps a more powerful model can make better predictions.  Let's explore that with some support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f595901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_metrics(\"Linear SVM Classifier-No CV\", linear_svm_metrics)\n",
    "print_model_metrics(\"Linear SVM Classifier-With CV\", linear_svm_cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13184ab",
   "metadata": {},
   "source": [
    "This is performing similarly to (but slightly better than) the logistic regression classifier.  Let's take a closer look at the most promising models and see if we can't find better hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438df4c",
   "metadata": {},
   "source": [
    "### 6. Fine Tuning\n",
    "\n",
    "\n",
    "Now that we've identified some promising models, we can begin fine tuning our model using GridSearchCV to train models with different combinations of hyperparameters (here we're just adjusting the regularization coefficient, C, for the linear support vector machine model from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c31069",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"C\":[1e-3, 1e-2, 1e-1, 1, 10, 100, 1e3, 1e4]}\n",
    "grid_search = GridSearchCV(linear_svm_clf, params, cv=3, scoring=\"f1\", refit=True) # refit=True retrains best_estimator on all other folds\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "grid_search.best_params_ #show the best hyperparams from the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0e420",
   "metadata": {},
   "source": [
    "At first, we started with order of magnitude differences in the hyper parameter grid.  Now, let's get a little more precise with our search grid by choosing closer values of C to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eeb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"C\":[75, 90, 100, 110, 125, 150]}\n",
    "grid_search = GridSearchCV(linear_svm_clf, params, cv=3, scoring=\"f1\", refit=True) # refit=True retrains best_estimator on all other folds\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "grid_search.best_params_ #show the best hyperparams from the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b531eec",
   "metadata": {},
   "source": [
    "We can see that our original estimate of 100 is still the optimal value of C.  Now, we can get the best estimator from the grid search, and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_clf = grid_search.best_estimator_\n",
    "best_svm_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c30ab6",
   "metadata": {},
   "source": [
    "Get the predictions on the training set and using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274487c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_best_svm = best_svm_clf.predict(X_train_prepared)\n",
    "y_train_pred_best_svm_cv = cross_val_predict(best_svm_clf, X_train_prepared, y_train, cv=3, method=\"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc00800",
   "metadata": {},
   "source": [
    "Get evaluation metrics for the best SVM classifier from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_metrics = get_model_metrics(y_train, y_train_pred_lin_svm)\n",
    "best_svm_cv_metrics = get_model_metrics(y_train, y_train_pred_lin_svm_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e70a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_metrics(\"Best Linear SVM Classifier-No CV\", best_svm_metrics)\n",
    "print_model_metrics(\"Best Linear SVM Classifier-With CV\", best_svm_cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc808153",
   "metadata": {},
   "source": [
    "As we can see, there's very similar performance on the training set and cross-validated models, suggesting a high degree of generalizability.  Now, all that remains is to test the performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_svm_clf.predict(X_test_prepared)\n",
    "test_metrics = get_model_metrics(y_test, y_test_pred)\n",
    "print_model_metrics(\"Linear SVM--Test Set\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "These are encouraging results!  We're successfully predicting 85.5% of all outcomes! Of the customers we classified as likely to file a claim, 77.6% of those did file claims.  Of all of the cusomters who filed claims, we correctly identified 72.4% of them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
